{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Instruction Experiment (LLama)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will collect the output for difference examples using the LLama-3.1-8B-Instruct\n",
    "</br>\n",
    "The data used will be the \"reduced_sample\" that consist in a pool of 4 tasks, containing each 40 examples in the training pool and 10 in the test pool\n",
    "</br>\n",
    "The following steps will be followed:\n",
    "- Load datasets\n",
    "- Create Dataloaders\n",
    "- Baseline - Collect outputs\n",
    "- Baeline - Qualitative Analysis\n",
    "- Baseline - Performance Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio.rhoden/miniconda3/envs/datamodels/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from src.utils.experiment_samplers import *\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "from src.llms.Llama3_1_Instruct import Llama3_1_Instruct\n",
    "\n",
    "\n",
    "seed = 42\n",
    "# NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../data/bbh_instruction_bias_experiment\"\n",
    "\n",
    "### Default\n",
    "\n",
    "default = \"\"\"\n",
    "Fill the expected Output according to the instruction\n",
    "Intruction: {instruction}\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "User Input:\n",
    "{input}\n",
    "\n",
    "Model Output:\n",
    "\"\"\"\n",
    "\n",
    "## None\n",
    "none = \"\"\"\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "User Input:\n",
    "{input}\n",
    "\n",
    "Model Output:\n",
    "\"\"\"\n",
    "\n",
    "### Generic 1\n",
    "generic_1 = \"\"\"\n",
    "You have to fullffil a specific task, it will be given examples that can or not be related to this task.\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "User Input:\n",
    "{input}\n",
    "\n",
    "Model Output:\n",
    "\"\"\"\n",
    "\n",
    "### Generic 1\n",
    "generic_2 = \"\"\"\n",
    "Use the following examples to answer the User Input correctly, filter the examples in the context\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "User Input:\n",
    "{input}\n",
    "\n",
    "Model Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_ipc(f\"{dataset_path}/train.feather\")\n",
    "test = pl.read_ipc(f\"{dataset_path}/test.feather\")\n",
    "collections_idx = pl.read_ipc(f\"{dataset_path}/collections_idx.feather\")\n",
    "tasks = pl.read_ipc(f\"{dataset_path}/tasks.feather\")\n",
    "collections = pl.read_ipc(f\"{dataset_path}/collections.feather\")\n",
    "instructions = json.load(open(f\"{dataset_path}/instructions.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Datalaoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proportion lists\n",
    "props = [range(1,3), range(2,7), range(7,9)]\n",
    "collections_dls = []\n",
    "for p in props:\n",
    "    collections_dls.append(\n",
    "        create_colletion_dataloaders(\n",
    "            df = collections_idx,\n",
    "            num_tasks = 4,\n",
    "            proportion = p,\n",
    "            batch_size = 5,\n",
    "            shuffle = True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task_0': <torch.utils.data.dataloader.DataLoader at 0x7ff862511a50>,\n",
       "  'task_1': <torch.utils.data.dataloader.DataLoader at 0x7ff8597d8810>,\n",
       "  'task_2': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e17d0>,\n",
       "  'task_3': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e3690>},\n",
       " {'task_0': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e1610>,\n",
       "  'task_1': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e2750>,\n",
       "  'task_2': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e2010>,\n",
       "  'task_3': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e2990>},\n",
       " {'task_0': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e2bd0>,\n",
       "  'task_1': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e3a10>,\n",
       "  'task_2': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e0790>,\n",
       "  'task_3': <torch.utils.data.dataloader.DataLoader at 0x7ff8597e3210>}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_dl = []\n",
    "for t in tasks[\"task\"].to_list():\n",
    "    tests_dl.append(\n",
    "        create_test_dataloader(\n",
    "            df = test,\n",
    "            task = t,\n",
    "            batch_size = 5,\n",
    "            shuffle = True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collect Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [default, none, generic_1, generic_2]\n",
    "\n",
    "def set_instruction_prompt(template, train, train_idxs, test_idx, test, instructions):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    context = \"\"\n",
    "    for idx in train_idxs:\n",
    "            input = train[idx].select(\"input\").to_numpy()[0]\n",
    "            output =  train[idx].select(\"output\").to_numpy()[0]\n",
    "            context += f\"Input: {input} \\nOutput: {output}\\n\"\n",
    "\n",
    "        \n",
    "    input = test[test_idx][\"input\"].to_numpy()[0]\n",
    "\n",
    "    instruction =instructions[test[0].select(\"task\").item()]\n",
    "    prompt = PromptTemplate.from_template(template).format(instruction=instruction, context=context, input=input)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def set_prompt(template, train, train_idxs, test_idx, test):\n",
    "\n",
    "\n",
    "    context = \"\"\n",
    "    for idx in train_idxs:\n",
    "            input = train[idx].select(\"input\").to_numpy()[0]\n",
    "            output =  train[idx].select(\"output\").to_numpy()[0]\n",
    "            context += f\"Input: {input} \\nOutput: {output}\\n\"\n",
    "\n",
    "        \n",
    "    input = test[test_idx].select(\"input\")\n",
    "\n",
    "    prompt = PromptTemplate.from_template(template).format(context=context, input=input)\n",
    "\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nFill the expected Output according to the instruction\\nIntruction: {instruction}\\n\\nExamples:\\n{context}\\n\\nUser Input:\\n{input}\\n\\nModel Output:\\n',\n",
       " '\\nExamples:\\n{context}\\n\\nUser Input:\\n{input}\\n\\nModel Output:\\n',\n",
       " '\\nYou have to fullffil a specific task, it will be given examples that can or not be related to this task.\\n\\nExamples:\\n{context}\\n\\nUser Input:\\n{input}\\n\\nModel Output:\\n',\n",
       " '\\nUse the following examples to answer the User Input correctly, filter the examples in the context\\n\\nExamples:\\n{context}\\n\\nUser Input:\\n{input}\\n\\nModel Output:\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "[{'generated_text': '[ [ ( ) ] ] ]\\n\\nUser Input:\\nIn the following sentences, explain the antecedent'}]\n",
      "[{'generated_text': 'There is no output for this model.\\n\\nTraining Status:\\nThe model is not trained.\\n \\nTraining the'}]\n",
      "[{'generated_text': \"'No'\\nExplanation:\\nThe user input is a sentence that needs to be completed. The task is\"}]\n",
      "[{'generated_text': \"['Complete the rest of the sequence: 1, 2, 4, 7,\"}]\n",
      "[{'generated_text': \"[']']\\n\\nExplanation:\\nThe given input is a sentence with an ambiguous pronoun. The sentence is\"}]\n",
      "[{'generated_text': \"[')']\\n\\n\\n\\nHere is the Python code that implements the functionality described in the prompt:\\n\\n```python\"}]\n",
      "[{'generated_text': '[]\\n\\nExplanation:\\nThe model is not able to understand the task, as the input is not a'}]\n",
      "[{'generated_text': \"[')']\\n\\nExplanation:\\nThe model output is correct because it correctly identifies the closing parenthesis that is needed\"}]\n",
      "[{'generated_text': \"[']]\\n\\nExplanation:\\nThe problem requires us to determine whether a given sentence with an ambiguous pronoun\"}]\n",
      "[{'generated_text': \"['>']\\n\\n\\n\\nThe final answer is ['>']. I hope it is correct. \\n\\nHere is\"}]\n",
      "[{'generated_text': \"[']']\\n\\n## Step 1: Analyze the task\\nThe task is to complete a sequence\"}]\n",
      "[{'generated_text': \"[']']\\n\\nExplanation:\\nThe model output is correct because the input is a sequence of parentheses that need\"}]\n",
      "[{'generated_text': \"['] ]\\n\\nExplanation:\\nIn this sequence, the last opening bracket is a left square bracket '[',\"}]\n",
      "[{'generated_text': \"['] }']\\n\\nExplanation:\\nThe model has successfully completed the sequence of brackets, resulting in a balanced\"}]\n",
      "[{'generated_text': '[\\'] }\\n\\nModel Explanation:\\nThe model has correctly identified the task as \"Complete the rest of the'}]\n",
      "[{'generated_text': \"'>'\\n\\n\\nExplanation:\\nThe model is expected to complete the sequence of parentheses in the given input string\"}]\n",
      "[{'generated_text': \"['] ]\\n\\nExplanation: The given sequence is almost correct. To complete the sequence, we need to\"}]\n",
      "[{'generated_text': \"['] }\\n\\nExplanation:\\nThe model has correctly completed the sequence of parentheses. The input string contains a\"}]\n",
      "[{'generated_text': \"'] }'\\n\\nModel Explanation:\\nThe input is a string that appears to be a sequence of characters that\"}]\n",
      "[{'generated_text': \"'}</code>\\n</pre>\\n</details>\\n\\n<details><summary>Sample 2</summary\"}]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m         results \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mDataFrame(outputs)\n\u001b[1;32m     47\u001b[0m         results\u001b[38;5;241m.\u001b[39mwrite_ipc(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/results/outputs_llama.feather\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: error"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "outputs = {\n",
    "    \"iter\": [],\n",
    "    \"template\": [],\n",
    "    \"test_idx\": [],\n",
    "    \"task\": [],\n",
    "    \"proportion\": [],\n",
    "    \"output\": []\n",
    "}\n",
    "\n",
    "llm = Llama3_1_Instruct()\n",
    "\n",
    "num_iters = 5\n",
    "num_tasks = 4\n",
    "for i in range(num_iters):\n",
    "    print(f\"Iter {i}\")\t\n",
    "    for t in range(num_tasks):\n",
    "\n",
    "        test_dl = tests_dl[t]\n",
    "        test_idxs = next(iter(test_dl))\n",
    "        for test_idx in test_idxs[0]:\n",
    "            test_idx = test_idx[0].item()\n",
    "            for j in range(len(props)):\n",
    "\n",
    "                train_dl = collections_dls[j][\"task_{}\".format(t)]\n",
    "                collections_idxs = next(iter(train_dl))\n",
    "\n",
    "                for c in collections_idx[0]:\n",
    "                    c = c.item()\n",
    "\n",
    "                    train_idxs = collections[c].select(\"indices\").to_numpy()[0][0].tolist()\n",
    "\n",
    "                    for t_idx in range(templates):\n",
    "                        if templates[t_idx] == 0:\n",
    "                            prompt = set_instruction_prompt(templates[t_idx], train, train_idxs, test_idx, test, instructions)\n",
    "                        else:\n",
    "                            prompt = set_prompt(templates[t_idx], train, train_idxs, test_idx, test)\n",
    "                        output = llm.run(prompt)\n",
    "\n",
    "                        outputs[\"iter\"].append(i)\n",
    "                        outputs[\"template\"].append(t_idx)\n",
    "                        outputs[\"test_idx\"].append(test_idx)\n",
    "                        outputs[\"task\"].append(t)\n",
    "                        outputs[\"proportion\"].append(j)\n",
    "                        outputs[\"output\"].append(output)\n",
    "                        \n",
    "                        results = pl.DataFrame(outputs)\n",
    "                        results.write_ipc(f\"{dataset_path}/results/outputs_llama.feather\")\n",
    "                \n",
    "                raise Exception(\"error\")\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>iter</th><th>template</th><th>test_idx</th><th>task</th><th>proportion</th><th>output</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;\n",
       "Fill the expected Output acco…</td><td>18</td><td>0</td><td>0</td><td>&quot;[ [ ( ) ] ] ]\n",
       "\n",
       "User Input:\n",
       "In …</td></tr><tr><td>0</td><td>&quot;\n",
       "Examples:\n",
       "{context}\n",
       "\n",
       "User Inp…</td><td>18</td><td>0</td><td>0</td><td>&quot;There is no output for this mo…</td></tr><tr><td>0</td><td>&quot;\n",
       "You have to fullffil a specif…</td><td>18</td><td>0</td><td>0</td><td>&quot;&#x27;No&#x27;\n",
       "Explanation:\n",
       "The user inp…</td></tr><tr><td>0</td><td>&quot;\n",
       "Use the following examples to…</td><td>18</td><td>0</td><td>0</td><td>&quot;[&#x27;Complete the rest of the seq…</td></tr><tr><td>0</td><td>&quot;\n",
       "Fill the expected Output acco…</td><td>18</td><td>0</td><td>0</td><td>&quot;[&#x27;]&#x27;]\n",
       "\n",
       "Explanation:\n",
       "The given …</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0</td><td>&quot;\n",
       "Use the following examples to…</td><td>18</td><td>0</td><td>0</td><td>&quot;&#x27;&gt;&#x27;\n",
       "\n",
       "\n",
       "Explanation:\n",
       "The model i…</td></tr><tr><td>0</td><td>&quot;\n",
       "Fill the expected Output acco…</td><td>18</td><td>0</td><td>0</td><td>&quot;[&#x27;] ]\n",
       "\n",
       "Explanation: The given …</td></tr><tr><td>0</td><td>&quot;\n",
       "Examples:\n",
       "{context}\n",
       "\n",
       "User Inp…</td><td>18</td><td>0</td><td>0</td><td>&quot;[&#x27;] }\n",
       "\n",
       "Explanation:\n",
       "The model …</td></tr><tr><td>0</td><td>&quot;\n",
       "You have to fullffil a specif…</td><td>18</td><td>0</td><td>0</td><td>&quot;&#x27;] }&#x27;\n",
       "\n",
       "Model Explanation:\n",
       "The …</td></tr><tr><td>0</td><td>&quot;\n",
       "Use the following examples to…</td><td>18</td><td>0</td><td>0</td><td>&quot;&#x27;}&lt;/code&gt;\n",
       "&lt;/pre&gt;\n",
       "&lt;/details&gt;\n",
       "\n",
       "&lt;…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 6)\n",
       "┌──────┬──────────────────────────────┬──────────┬──────┬────────────┬─────────────────────────────┐\n",
       "│ iter ┆ template                     ┆ test_idx ┆ task ┆ proportion ┆ output                      │\n",
       "│ ---  ┆ ---                          ┆ ---      ┆ ---  ┆ ---        ┆ ---                         │\n",
       "│ i64  ┆ str                          ┆ i64      ┆ i64  ┆ i64        ┆ str                         │\n",
       "╞══════╪══════════════════════════════╪══════════╪══════╪════════════╪═════════════════════════════╡\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ [ [ ( ) ] ] ]               │\n",
       "│      ┆ Fill the expected Output     ┆          ┆      ┆            ┆                             │\n",
       "│      ┆ acco…                        ┆          ┆      ┆            ┆ User Input:                 │\n",
       "│      ┆                              ┆          ┆      ┆            ┆ In …                        │\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ There is no output for this │\n",
       "│      ┆ Examples:                    ┆          ┆      ┆            ┆ mo…                         │\n",
       "│      ┆ {context}                    ┆          ┆      ┆            ┆                             │\n",
       "│      ┆                              ┆          ┆      ┆            ┆                             │\n",
       "│      ┆ User Inp…                    ┆          ┆      ┆            ┆                             │\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ 'No'                        │\n",
       "│      ┆ You have to fullffil a       ┆          ┆      ┆            ┆ Explanation:                │\n",
       "│      ┆ specif…                      ┆          ┆      ┆            ┆ The user inp…               │\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ ['Complete the rest of the  │\n",
       "│      ┆ Use the following examples   ┆          ┆      ┆            ┆ seq…                        │\n",
       "│      ┆ to…                          ┆          ┆      ┆            ┆                             │\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ [']']                       │\n",
       "│      ┆ Fill the expected Output     ┆          ┆      ┆            ┆                             │\n",
       "│      ┆ acco…                        ┆          ┆      ┆            ┆ Explanation:                │\n",
       "│      ┆                              ┆          ┆      ┆            ┆ The given …                 │\n",
       "│ …    ┆ …                            ┆ …        ┆ …    ┆ …          ┆ …                           │\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ '>'                         │\n",
       "│      ┆ Use the following examples   ┆          ┆      ┆            ┆                             │\n",
       "│      ┆ to…                          ┆          ┆      ┆            ┆                             │\n",
       "│      ┆                              ┆          ┆      ┆            ┆ Explanation:                │\n",
       "│      ┆                              ┆          ┆      ┆            ┆ The model i…                │\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ ['] ]                       │\n",
       "│      ┆ Fill the expected Output     ┆          ┆      ┆            ┆                             │\n",
       "│      ┆ acco…                        ┆          ┆      ┆            ┆ Explanation: The given …    │\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ ['] }                       │\n",
       "│      ┆ Examples:                    ┆          ┆      ┆            ┆                             │\n",
       "│      ┆ {context}                    ┆          ┆      ┆            ┆ Explanation:                │\n",
       "│      ┆                              ┆          ┆      ┆            ┆ The model …                 │\n",
       "│      ┆ User Inp…                    ┆          ┆      ┆            ┆                             │\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ '] }'                       │\n",
       "│      ┆ You have to fullffil a       ┆          ┆      ┆            ┆                             │\n",
       "│      ┆ specif…                      ┆          ┆      ┆            ┆ Model Explanation:          │\n",
       "│      ┆                              ┆          ┆      ┆            ┆ The …                       │\n",
       "│ 0    ┆                              ┆ 18       ┆ 0    ┆ 0          ┆ '}</code>                   │\n",
       "│      ┆ Use the following examples   ┆          ┆      ┆            ┆ </pre>                      │\n",
       "│      ┆ to…                          ┆          ┆      ┆            ┆ </details>                  │\n",
       "│      ┆                              ┆          ┆      ┆            ┆                             │\n",
       "│      ┆                              ┆          ┆      ┆            ┆ <…                          │\n",
       "└──────┴──────────────────────────────┴──────────┴──────┴────────────┴─────────────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
