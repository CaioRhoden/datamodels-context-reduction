{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Insturction Analysis - Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prepare the data that will be needed to do the studies described in the README\n",
    "</br> Here we will execute the following steps:\n",
    "- Create the collections dataset with indices, string and proportions by task and test dataframe\n",
    "- Create a DataLoader to sample collections based on it's proportion to target task\n",
    "- Create a DataLoader to sample X test samples by task\n",
    "- Create the three different prompts to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "data_path = \"../../data/bbh/datamodels/reduced_sample\"\n",
    "save_path = \"../../data/bbh_instruction_bias_experiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Collections, Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(f\"{data_path}/train_collection.h5\", \"r\")\n",
    "collections = f[\"train_collection\"][:]\n",
    "train = pl.read_csv(f\"{data_path}/train_set.csv\").with_columns(pl.arange(0, pl.len()).alias(\"index\"))\n",
    "test = pl.read_csv(f\"{data_path}/test_set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = train[\"task\"].unique()\n",
    "collections_idx = pl.DataFrame({\"collection_idx\": [i for i in range(len(collections))], \"indices\": [indices.tolist() for indices in collections]})\n",
    "_exploded = collections_idx.clone()\n",
    "_exploded = _exploded.explode(\"indices\").join(train, left_on=\"indices\", right_on=\"index\")\n",
    "\n",
    "for i in range(0, len(tasks)):\n",
    "    _exploded = _exploded.with_columns(pl.col(\"task\").str.contains(tasks[i]).alias(f\"prop_task_{i}\"))\n",
    "\n",
    "collections_idx = (\n",
    "    _exploded\n",
    "    .group_by(\"collection_idx\")\n",
    "    .agg(\n",
    "        count_task_0 = pl.col(\"prop_task_0\").sum(),\n",
    "        count_task_1 = pl.col(\"prop_task_1\").sum(),\n",
    "        count_task_2 = pl.col(\"prop_task_2\").sum(),\n",
    "        count_task_3 = pl.col(\"prop_task_3\").sum(),\n",
    "    )\n",
    ")\n",
    "\n",
    "#TODO: Create \"task_idx\" column in Polars base don the arr tasks\n",
    "\n",
    "def return_task_idx(x):\n",
    "    task_to_idx = {task: idx for idx, task in enumerate(tasks)}\n",
    "    return task_to_idx[x]\n",
    "task_to_idx = {task: idx for idx, task in enumerate(tasks)}\n",
    "\n",
    "test = test.with_columns([\n",
    "    pl.col(\"task\").replace(task_to_idx).cast(int).alias(\"task_idx\")\n",
    "])\n",
    "\n",
    "train = train.with_columns([\n",
    "    pl.col(\"task\").replace(task_to_idx).cast(int).alias(\"task_idx\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving files\n",
    "collections_idx.write_ipc(f\"{save_path}/collections_idx.feather\")\n",
    "train.write_ipc(f\"{save_path}/train.feather\")\n",
    "test.write_ipc(f\"{save_path}/test.feather\")\n",
    "pl.DataFrame({\"task\": tasks}).write_ipc(f\"{save_path}/tasks.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Collections Dataloader\n",
    "\n",
    "What it will be done here will be transformed into a utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>collection_idx</th><th>count_task_0</th><th>count_task_1</th><th>count_task_2</th><th>count_task_3</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>3805</td><td>2</td><td>2</td><td>1</td><td>3</td></tr><tr><td>3150</td><td>1</td><td>6</td><td>0</td><td>1</td></tr><tr><td>2757</td><td>3</td><td>3</td><td>1</td><td>1</td></tr><tr><td>5377</td><td>2</td><td>3</td><td>1</td><td>2</td></tr><tr><td>3281</td><td>1</td><td>2</td><td>2</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────────────┬──────────────┬──────────────┬──────────────┬──────────────┐\n",
       "│ collection_idx ┆ count_task_0 ┆ count_task_1 ┆ count_task_2 ┆ count_task_3 │\n",
       "│ ---            ┆ ---          ┆ ---          ┆ ---          ┆ ---          │\n",
       "│ i64            ┆ u32          ┆ u32          ┆ u32          ┆ u32          │\n",
       "╞════════════════╪══════════════╪══════════════╪══════════════╪══════════════╡\n",
       "│ 3805           ┆ 2            ┆ 2            ┆ 1            ┆ 3            │\n",
       "│ 3150           ┆ 1            ┆ 6            ┆ 0            ┆ 1            │\n",
       "│ 2757           ┆ 3            ┆ 3            ┆ 1            ┆ 1            │\n",
       "│ 5377           ┆ 2            ┆ 3            ┆ 1            ┆ 2            │\n",
       "│ 3281           ┆ 1            ┆ 2            ┆ 2            ┆ 3            │\n",
       "└────────────────┴──────────────┴──────────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections_idx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colletion_dataloaders(\n",
    "    df: pl.DataFrame,\n",
    "    num_tasks: int,\n",
    "    proportion: range,\n",
    "    batch_size: int,\n",
    "    shuffle: bool = True,  \n",
    "):\n",
    "    \n",
    "    dataloaders = {}\n",
    "\n",
    "    for i in range(num_tasks):\n",
    "        task = i\n",
    "        _df = (\n",
    "            df\n",
    "            .clone()\n",
    "            .filter(pl.col(f\"count_task_{task}\").is_in(proportion))\n",
    "            .select([\"collection_idx\"])\n",
    "        )\n",
    "\n",
    "        dl = DataLoader(\n",
    "            TensorDataset(_df.to_torch()),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "\n",
    "        dataloaders[f\"task_{task}\"] = dl\n",
    "\n",
    "    return dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_0': <torch.utils.data.dataloader.DataLoader at 0x7f588262fc10>,\n",
       " 'task_1': <torch.utils.data.dataloader.DataLoader at 0x7f56f935a910>,\n",
       " 'task_2': <torch.utils.data.dataloader.DataLoader at 0x7f56f935b410>,\n",
       " 'task_3': <torch.utils.data.dataloader.DataLoader at 0x7f56f9358150>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = create_colletion_dataloaders(\n",
    "    collections_idx,\n",
    "    num_tasks=4,\n",
    "    proportion=range(7, 8),\n",
    "    batch_size=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Test Dataloaders\n",
    "\n",
    "What it will be done here will be transformed into a utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataloader(\n",
    "    df: pl.DataFrame,\n",
    "    task: str,\n",
    "    batch_size: int,\n",
    "    shuffle: bool = True,\n",
    "):\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    _df = (\n",
    "        df\n",
    "        .clone()\n",
    "        .with_columns(pl.arange(0, pl.len()).alias(\"idx\"))\n",
    "        .filter(pl.col(f\"task\").eq(task))\n",
    "        .select([\"idx\"])\n",
    "    )\n",
    "\n",
    "    dl = DataLoader(\n",
    "            TensorDataset(_df.to_torch()),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "\n",
    "\n",
    "    return dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[30],\n",
       "         [34],\n",
       "         [31],\n",
       "         [39]])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = create_test_dataloader(test, task=\"word_sorting\", batch_size=4, shuffle=True)\n",
    "next(iter(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Default\n",
    "\n",
    "default = \"\"\"\n",
    "Fill the expected Output according to the instruction\n",
    "Intruction: {instruction}\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "User Input:\n",
    "{input}\n",
    "\n",
    "Model Output:\n",
    "\"\"\"\n",
    "\n",
    "## None\n",
    "none = \"\"\"\"\"\"\n",
    "\n",
    "### Generic 1\n",
    "generic_1 = \"\"\"\n",
    "You have to fullffil a specific task, it will be given examples that can or not be related to this task.\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "User Input:\n",
    "{input}\n",
    "\n",
    "Model Output:\n",
    "\"\"\"\n",
    "\n",
    "### Generic 1\n",
    "generic_2 = \"\"\"\n",
    "Use the following examples to answer the User Input correctly, filter the examples in the context\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "User Input:\n",
    "{input}\n",
    "\n",
    "Model Output:\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
