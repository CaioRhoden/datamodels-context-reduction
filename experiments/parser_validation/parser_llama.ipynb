{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Instruction Experiment (LLama)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will collect the output for difference examples using the LLama-3.1-8B-Instruct\n",
    "</br>\n",
    "The data used will be the \"reduced_sample\" that consist in a pool of 4 tasks, containing each 40 examples in the training pool and 10 in the test pool\n",
    "</br>\n",
    "The following steps will be followed:\n",
    "- Load datasets\n",
    "- Create Dataloaders\n",
    "- Baseline - Collect outputs\n",
    "- Baeline - Qualitative Analysis\n",
    "- Baseline - Performance Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio.rhoden/miniconda3/envs/datamodels/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from src.utils.experiment_samplers import *\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "from src.llms.ParserLlama import ParserLlama\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "\n",
    "seed = 42\n",
    "# NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = SimpleJsonOutputParser()\n",
    "parser_instruction = \"Return a JSON object with an 'answer' key that answers straight forward the user input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../data/bbh_instruction_bias_experiment\"\n",
    "\n",
    "### Default\n",
    "\n",
    "\n",
    "default_obj = \"\"\"\n",
    "Fill the expected Output according to the instruction. Just anwer the input.\n",
    "Intruction: {instruction}\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "User Input:\n",
    "{input}\n",
    "\n",
    "Model Output:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "### Generic 1\n",
    "generic_1_obj = \"\"\"\n",
    "You have to fullffil a specific task, it will be given examples that can or not be related to this task. Just answer the User Input.\n",
    "\n",
    "Examples:\n",
    "{context}\n",
    "\n",
    "User Input:\n",
    "{input}\n",
    "\n",
    "Model Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_ipc(f\"{dataset_path}/train.feather\")\n",
    "test = pl.read_ipc(f\"{dataset_path}/test.feather\")\n",
    "collections_idx = pl.read_ipc(f\"{dataset_path}/collections_idx.feather\")\n",
    "tasks = pl.read_ipc(f\"{dataset_path}/tasks.feather\")\n",
    "collections = pl.read_ipc(f\"{dataset_path}/collections.feather\")\n",
    "instructions = json.load(open(f\"{dataset_path}/instructions.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Datalaoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proportion lists\n",
    "props = [range(0, 1),  range(7,9)]\n",
    "collections_dls = []\n",
    "for p in props:\n",
    "    collections_dls.append(\n",
    "        create_colletion_dataloaders(\n",
    "            df = collections_idx,\n",
    "            num_tasks = 4,\n",
    "            proportion = p,\n",
    "            batch_size = 5,\n",
    "            shuffle = True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_dl = []\n",
    "for t in tasks[\"task\"].to_list():\n",
    "    tests_dl.append(\n",
    "        create_test_dataloader(\n",
    "            df = test,\n",
    "            task = t,\n",
    "            batch_size = 5,\n",
    "            shuffle = True\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collect Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [ default_obj, generic_1_obj]\n",
    "\n",
    "def set_instruction_prompt(template, train, train_idxs, test_idx, test, instructions):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    context = \"\"\n",
    "    for idx in train_idxs:\n",
    "            input = train[idx].select(\"input\").to_numpy()[0]\n",
    "            output =  train[idx].select(\"output\").to_numpy()[0]\n",
    "            context += f\"Input: {input} \\nOutput: {output}\\n\"\n",
    "\n",
    "        \n",
    "    input = test[test_idx][\"input\"].to_numpy()[0]\n",
    "\n",
    "    instruction =instructions[test[0].select(\"task\").item()]\n",
    "    prompt = PromptTemplate.from_template(template).format(instruction=instruction, context=context, input=input)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def set_prompt(template, train, train_idxs, test_idx, test):\n",
    "\n",
    "\n",
    "    context = \"\"\n",
    "    for idx in train_idxs:\n",
    "            input = train[idx].select(\"input\").to_numpy()[0]\n",
    "            output =  train[idx].select(\"output\").to_numpy()[0]\n",
    "            context += f\"Input: {input} \\nOutput: {output}\\n\"\n",
    "\n",
    "        \n",
    "    input = test[test_idx].select(\"input\")\n",
    "\n",
    "    prompt = PromptTemplate.from_template(template).format(context=context, input=input)\n",
    "\n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "[{'role': 'system', 'content': \"You have to answer the question from the user that will be passed with some examples, not all of them necessarily useful. Return a JSON object with an 'answer' key that answers straight forward the user input\"}, {'role': 'user', 'content': 'Question: \\nFill the expected Output according to the instruction. Just anwer the input.\\nIntruction: given a sentence with an ambigious pronoun, either determine whether the sentence is inherently ambiguous (i.e., the thing that the pronoun refers to cannot be inferred by given information) or, if the pronoun can be implicitly deduced, state the antecedent of the pronoun (i.e., the noun to which the pronoun refers).\\n\\nExamples:\\nInput: [\\'Question: Jaymie tells the truth. Millicent says Jaymie lies. Millie says Millicent tells the truth. Vina says Millie lies. Leda says Vina tells the truth. Does Leda tell the truth?\\'] \\nOutput: [\\'Yes\\']\\nInput: [\"In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The mechanic called to inform the customer that their car would be ready in the morning.\\\\nOptions:\\\\n(A) It was the mechanic\\'s car\\\\n(B) It was the customer\\'s car\\\\n(C) Ambiguous\"] \\nOutput: [\\'(B)\\']\\nInput: [\\'In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: Alex tells us that she could not meet.\\\\nOptions:\\\\n(A) Alex could not meet\\\\n(B) We could not meet\\\\n(C) Ambiguous\\'] \\nOutput: [\\'(A)\\']\\nInput: [\\'In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The technician told the customer that they could pay with cash.\\\\nOptions:\\\\n(A) The technician could pay\\\\n(B) The customer could pay\\\\n(C) Ambiguous\\'] \\nOutput: [\\'(B)\\']\\nInput: [\\'Sort the following words alphabetically: List: matte game aldebaran inkling fiberboard pulsate lakeside shape mcgee watchworks entrepreneurial boxwood peruse backyard cabbage polyhedra lightface rowley rae invincible\\'] \\nOutput: [\\'aldebaran backyard boxwood cabbage entrepreneurial fiberboard game inkling invincible lakeside lightface matte mcgee peruse polyhedra pulsate rae rowley shape watchworks\\']\\nInput: [\\'Question: Gwenn tells the truth. Lorine says Gwenn lies. Antwan says Lorine tells the truth. Elanor says Antwan tells the truth. Delfina says Elanor tells the truth. Does Delfina tell the truth?\\'] \\nOutput: [\\'No\\']\\nInput: [\\'In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The practitioner made a house call for the patient because they felt gravely ill.\\\\nOptions:\\\\n(A) The practitioner felt ill\\\\n(B) The patient felt ill\\\\n(C) Ambiguous\\'] \\nOutput: [\\'(B)\\']\\nInput: [\\'Sort the following words alphabetically: List: broaden envy\\'] \\nOutput: [\\'broaden envy\\']\\n\\n\\nUser Input:\\nComplete the rest of the sequence, making sure that the parentheses are closed properly. Input: < < [ ( ) ] >\\n\\nModel Output:\\n'}]\n",
      "[{'role': 'system', 'content': \"You have to answer the question from the user that will be passed with some examples, not all of them necessarily useful. Return a JSON object with an 'answer' key that answers straight forward the user input\"}, {'role': 'user', 'content': 'Question: \\nYou have to fullffil a specific task, it will be given examples that can or not be related to this task. Just answer the User Input.\\n\\nExamples:\\nInput: [\\'Question: Jaymie tells the truth. Millicent says Jaymie lies. Millie says Millicent tells the truth. Vina says Millie lies. Leda says Vina tells the truth. Does Leda tell the truth?\\'] \\nOutput: [\\'Yes\\']\\nInput: [\"In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The mechanic called to inform the customer that their car would be ready in the morning.\\\\nOptions:\\\\n(A) It was the mechanic\\'s car\\\\n(B) It was the customer\\'s car\\\\n(C) Ambiguous\"] \\nOutput: [\\'(B)\\']\\nInput: [\\'In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: Alex tells us that she could not meet.\\\\nOptions:\\\\n(A) Alex could not meet\\\\n(B) We could not meet\\\\n(C) Ambiguous\\'] \\nOutput: [\\'(A)\\']\\nInput: [\\'In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The technician told the customer that they could pay with cash.\\\\nOptions:\\\\n(A) The technician could pay\\\\n(B) The customer could pay\\\\n(C) Ambiguous\\'] \\nOutput: [\\'(B)\\']\\nInput: [\\'Sort the following words alphabetically: List: matte game aldebaran inkling fiberboard pulsate lakeside shape mcgee watchworks entrepreneurial boxwood peruse backyard cabbage polyhedra lightface rowley rae invincible\\'] \\nOutput: [\\'aldebaran backyard boxwood cabbage entrepreneurial fiberboard game inkling invincible lakeside lightface matte mcgee peruse polyhedra pulsate rae rowley shape watchworks\\']\\nInput: [\\'Question: Gwenn tells the truth. Lorine says Gwenn lies. Antwan says Lorine tells the truth. Elanor says Antwan tells the truth. Delfina says Elanor tells the truth. Does Delfina tell the truth?\\'] \\nOutput: [\\'No\\']\\nInput: [\\'In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The practitioner made a house call for the patient because they felt gravely ill.\\\\nOptions:\\\\n(A) The practitioner felt ill\\\\n(B) The patient felt ill\\\\n(C) Ambiguous\\'] \\nOutput: [\\'(B)\\']\\nInput: [\\'Sort the following words alphabetically: List: broaden envy\\'] \\nOutput: [\\'broaden envy\\']\\n\\n\\nUser Input:\\nshape: (1, 1)\\n┌─────────────────────────────────┐\\n│ input                           │\\n│ ---                             │\\n│ str                             │\\n╞═════════════════════════════════╡\\n│ Complete the rest of the seque… │\\n└─────────────────────────────────┘\\n\\nModel Output:\\n'}]\n",
      "[{'role': 'system', 'content': \"You have to answer the question from the user that will be passed with some examples, not all of them necessarily useful. Return a JSON object with an 'answer' key that answers straight forward the user input\"}, {'role': 'user', 'content': 'Question: \\nFill the expected Output according to the instruction. Just anwer the input.\\nIntruction: given a sentence with an ambigious pronoun, either determine whether the sentence is inherently ambiguous (i.e., the thing that the pronoun refers to cannot be inferred by given information) or, if the pronoun can be implicitly deduced, state the antecedent of the pronoun (i.e., the noun to which the pronoun refers).\\n\\nExamples:\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: { ( < { < ( ) > } >\\'] \\nOutput: [\\') }\\']\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: ( { [ [ { } ] ] }\\'] \\nOutput: [\\')\\']\\nInput: [\\'Sort the following words alphabetically: List: matte game aldebaran inkling fiberboard pulsate lakeside shape mcgee watchworks entrepreneurial boxwood peruse backyard cabbage polyhedra lightface rowley rae invincible\\'] \\nOutput: [\\'aldebaran backyard boxwood cabbage entrepreneurial fiberboard game inkling invincible lakeside lightface matte mcgee peruse polyhedra pulsate rae rowley shape watchworks\\']\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: < < { ( < ( ) > ) }\\'] \\nOutput: [\\'> >\\']\\nInput: [\"In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The manager asked the employee to not forget their car.\\\\nOptions:\\\\n(A) It was the manager\\'s car\\\\n(B) It was the employee\\'s car\\\\n(C) Ambiguous\"] \\nOutput: [\\'(C)\\']\\nInput: [\\'Question: Kandi tells the truth. Ryan says Kandi lies. Michaela says Ryan tells the truth. Sima says Michaela lies. Andree says Sima tells the truth. Does Andree tell the truth?\\'] \\nOutput: [\\'Yes\\']\\nInput: [\\'Sort the following words alphabetically: List: thrill splutter panicking scorch same dot prod obstetric malton onus drumhead delmarva barn embezzle it&t damp guru subsist entirety greene\\'] \\nOutput: [\\'barn damp delmarva dot drumhead embezzle entirety greene guru it&t malton obstetric onus panicking prod same scorch splutter subsist thrill\\']\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: { < < ( )\\'] \\nOutput: [\\'> > }\\']\\n\\n\\nUser Input:\\nComplete the rest of the sequence, making sure that the parentheses are closed properly. Input: < < [ ( ) ] >\\n\\nModel Output:\\n'}]\n",
      "[{'role': 'system', 'content': \"You have to answer the question from the user that will be passed with some examples, not all of them necessarily useful. Return a JSON object with an 'answer' key that answers straight forward the user input\"}, {'role': 'user', 'content': 'Question: \\nYou have to fullffil a specific task, it will be given examples that can or not be related to this task. Just answer the User Input.\\n\\nExamples:\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: { ( < { < ( ) > } >\\'] \\nOutput: [\\') }\\']\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: ( { [ [ { } ] ] }\\'] \\nOutput: [\\')\\']\\nInput: [\\'Sort the following words alphabetically: List: matte game aldebaran inkling fiberboard pulsate lakeside shape mcgee watchworks entrepreneurial boxwood peruse backyard cabbage polyhedra lightface rowley rae invincible\\'] \\nOutput: [\\'aldebaran backyard boxwood cabbage entrepreneurial fiberboard game inkling invincible lakeside lightface matte mcgee peruse polyhedra pulsate rae rowley shape watchworks\\']\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: < < { ( < ( ) > ) }\\'] \\nOutput: [\\'> >\\']\\nInput: [\"In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The manager asked the employee to not forget their car.\\\\nOptions:\\\\n(A) It was the manager\\'s car\\\\n(B) It was the employee\\'s car\\\\n(C) Ambiguous\"] \\nOutput: [\\'(C)\\']\\nInput: [\\'Question: Kandi tells the truth. Ryan says Kandi lies. Michaela says Ryan tells the truth. Sima says Michaela lies. Andree says Sima tells the truth. Does Andree tell the truth?\\'] \\nOutput: [\\'Yes\\']\\nInput: [\\'Sort the following words alphabetically: List: thrill splutter panicking scorch same dot prod obstetric malton onus drumhead delmarva barn embezzle it&t damp guru subsist entirety greene\\'] \\nOutput: [\\'barn damp delmarva dot drumhead embezzle entirety greene guru it&t malton obstetric onus panicking prod same scorch splutter subsist thrill\\']\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: { < < ( )\\'] \\nOutput: [\\'> > }\\']\\n\\n\\nUser Input:\\nshape: (1, 1)\\n┌─────────────────────────────────┐\\n│ input                           │\\n│ ---                             │\\n│ str                             │\\n╞═════════════════════════════════╡\\n│ Complete the rest of the seque… │\\n└─────────────────────────────────┘\\n\\nModel Output:\\n'}]\n",
      "[{'role': 'system', 'content': \"You have to answer the question from the user that will be passed with some examples, not all of them necessarily useful. Return a JSON object with an 'answer' key that answers straight forward the user input\"}, {'role': 'user', 'content': 'Question: \\nFill the expected Output according to the instruction. Just anwer the input.\\nIntruction: given a sentence with an ambigious pronoun, either determine whether the sentence is inherently ambiguous (i.e., the thing that the pronoun refers to cannot be inferred by given information) or, if the pronoun can be implicitly deduced, state the antecedent of the pronoun (i.e., the noun to which the pronoun refers).\\n\\nExamples:\\nInput: [\\'Sort the following words alphabetically: List: thirteenth tinfoil thimble snuff ernie pow celebrity abuilding indiscoverable chigger burgher synchronous yap medlar exorcism newsboy\\'] \\nOutput: [\\'abuilding burgher celebrity chigger ernie exorcism indiscoverable medlar newsboy pow snuff synchronous thimble thirteenth tinfoil yap\\']\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: [ ] { ( { < > } ) } [ ( ) ] { } [ { { ( < > ) } <\\'] \\nOutput: [\\'> } ]\\']\\nInput: [\"In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The customer and the chef discuss her culinary training.\\\\nOptions:\\\\n(A) It is the customer\\'s culinary training\\\\n(B) It is the chef\\'s culinary training\\\\n(C) Ambiguous\"] \\nOutput: [\\'(B)\\']\\nInput: [\\'Sort the following words alphabetically: List: stitch steelmake indomitable wigging cubby sheaf pique thymine exotica good mental brake nick rajah lineage choose bunny drone chevalier\\'] \\nOutput: [\\'brake bunny chevalier choose cubby drone exotica good indomitable lineage mental nick pique rajah sheaf steelmake stitch thymine wigging\\']\\nInput: [\\'In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The surgeon warned the nurse that she needed more time to prepare.\\\\nOptions:\\\\n(A) The surgeon needed more time\\\\n(B) The nurse needed more time\\\\n(C) Ambiguous\\'] \\nOutput: [\\'(C)\\']\\nInput: [\\'Complete the rest of the sequence, making sure that the parentheses are closed properly. Input: [ ( [ ( [ < ( ) > [ < { } { [ ] } [ ] [ ] > { ( < { < > } > ) } ] ] ) ] )\\'] \\nOutput: [\\']\\']\\nInput: [\\'In the following sentences, explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.\\\\nSentence: The technician told the customer that they could pay with cash.\\\\nOptions:\\\\n(A) The technician could pay\\\\n(B) The customer could pay\\\\n(C) Ambiguous\\'] \\nOutput: [\\'(B)\\']\\nInput: [\\'Sort the following words alphabetically: List: statutory feed spavin hecatomb pestle plume figural pasty giveth incense undulate middle blackstone tel obstinacy toothpaste hunt sinkhole\\'] \\nOutput: [\\'blackstone feed figural giveth hecatomb hunt incense middle obstinacy pasty pestle plume sinkhole spavin statutory tel toothpaste undulate\\']\\n\\n\\nUser Input:\\nComplete the rest of the sequence, making sure that the parentheses are closed properly. Input: < < [ ( ) ] >\\n\\nModel Output:\\n'}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unexpected value while building Series of type String; found value of type List(String): [\">\"]\n\nHint: Try setting `strict=False` to allow passing data with mixed types.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/datamodels/lib/python3.11/site-packages/polars/_utils/construction/series.py:319\u001b[0m, in \u001b[0;36m_construct_series_with_fallbacks\u001b[0;34m(constructor, name, values, dtype, strict)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mOverflowError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m# # This retry with i64 is related to https://github.com/pola-rs/polars/issues/17231\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# # Essentially, when given a [0, u64::MAX] then it would Overflow.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be converted to 'PyString'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproportion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(j)\n\u001b[1;32m     48\u001b[0m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[0;32m---> 50\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m results\u001b[38;5;241m.\u001b[39mwrite_ipc(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/results/llama_parser.feather\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/datamodels/lib/python3.11/site-packages/polars/dataframe/frame.py:368\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, schema, schema_overrides, strict, orient, infer_schema_length, nan_to_null)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m dict_to_pydf(\n\u001b[1;32m    364\u001b[0m         {}, schema\u001b[38;5;241m=\u001b[39mschema, schema_overrides\u001b[38;5;241m=\u001b[39mschema_overrides\n\u001b[1;32m    365\u001b[0m     )\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_pydf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnan_to_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_to_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, Sequence)):\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m sequence_to_pydf(\n\u001b[1;32m    378\u001b[0m         data,\n\u001b[1;32m    379\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m         infer_schema_length\u001b[38;5;241m=\u001b[39minfer_schema_length,\n\u001b[1;32m    384\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/datamodels/lib/python3.11/site-packages/polars/_utils/construction/dataframe.py:161\u001b[0m, in \u001b[0;36mdict_to_pydf\u001b[0;34m(data, schema, schema_overrides, strict, nan_to_null, allow_multithreaded)\u001b[0m\n\u001b[1;32m    148\u001b[0m     data_series \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    149\u001b[0m         pl\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[1;32m    150\u001b[0m             name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m column_names\n\u001b[1;32m    157\u001b[0m     ]\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     data_series \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    160\u001b[0m         s\u001b[38;5;241m.\u001b[39m_s\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_expand_dict_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnan_to_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_to_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    167\u001b[0m     ]\n\u001b[1;32m    169\u001b[0m data_series \u001b[38;5;241m=\u001b[39m _handle_columns_arg(data_series, columns\u001b[38;5;241m=\u001b[39mcolumn_names, from_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m pydf \u001b[38;5;241m=\u001b[39m PyDataFrame(data_series)\n",
      "File \u001b[0;32m~/miniconda3/envs/datamodels/lib/python3.11/site-packages/polars/_utils/construction/dataframe.py:390\u001b[0m, in \u001b[0;36m_expand_dict_values\u001b[0;34m(data, schema_overrides, strict, order, nan_to_null)\u001b[0m\n\u001b[1;32m    387\u001b[0m     updated_data[name] \u001b[38;5;241m=\u001b[39m s\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arrlen(val) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m _is_generator(val):\n\u001b[0;32m--> 390\u001b[0m     updated_data[name] \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnan_to_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_to_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(  \u001b[38;5;66;03m# type: ignore[redundant-expr]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m     val, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, date, datetime, time, timedelta)\n\u001b[1;32m    399\u001b[0m ):\n\u001b[1;32m    400\u001b[0m     updated_data[name] \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[1;32m    401\u001b[0m         val, array_len, dtype\u001b[38;5;241m=\u001b[39mdtype, eager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     )\u001b[38;5;241m.\u001b[39malias(name)\n",
      "File \u001b[0;32m~/miniconda3/envs/datamodels/lib/python3.11/site-packages/polars/series/series.py:289\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, name, values, dtype, strict, nan_to_null)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Sequence):\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_s \u001b[38;5;241m=\u001b[39m \u001b[43msequence_to_pyseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnan_to_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_to_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_s \u001b[38;5;241m=\u001b[39m sequence_to_pyseries(name, [], dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/datamodels/lib/python3.11/site-packages/polars/_utils/construction/series.py:304\u001b[0m, in \u001b[0;36msequence_to_pyseries\u001b[0;34m(name, values, dtype, strict, nan_to_null)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m PySeries\u001b[38;5;241m.\u001b[39mnew_from_any_values(name, values, strict\u001b[38;5;241m=\u001b[39mstrict)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_construct_series_with_fallbacks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/datamodels/lib/python3.11/site-packages/polars/_utils/construction/series.py:332\u001b[0m, in \u001b[0;36m_construct_series_with_fallbacks\u001b[0;34m(constructor, name, values, dtype, strict)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _construct_series_with_fallbacks(\n\u001b[1;32m    329\u001b[0m         PySeries\u001b[38;5;241m.\u001b[39mnew_opt_u64, name, values, dtype, strict\u001b[38;5;241m=\u001b[39mstrict\n\u001b[1;32m    330\u001b[0m     )\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPySeries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_from_any_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PySeries\u001b[38;5;241m.\u001b[39mnew_from_any_values_and_dtype(\n\u001b[1;32m    335\u001b[0m         name, values, dtype, strict\u001b[38;5;241m=\u001b[39mstrict\n\u001b[1;32m    336\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: unexpected value while building Series of type String; found value of type List(String): [\">\"]\n\nHint: Try setting `strict=False` to allow passing data with mixed types."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "outputs = {\n",
    "    \"iter\": [],\n",
    "    \"template\": [],\n",
    "    \"test_idx\": [],\n",
    "    \"task\": [],\n",
    "    \"proportion\": [],\n",
    "    \"output\": []\n",
    "}\n",
    "\n",
    "llm = ParserLlama()\n",
    "\n",
    "num_iters = 5\n",
    "num_tasks = 4\n",
    "for i in range(num_iters):\n",
    "    print(f\"Iter {i}\")\t\n",
    "    for t in range(num_tasks):\n",
    "\n",
    "        test_dl = tests_dl[t]\n",
    "        test_idxs = next(iter(test_dl))\n",
    "        for test_idx in test_idxs[0]:\n",
    "            test_idx = test_idx[0].item()\n",
    "            for j in range(len(props)):\n",
    "\n",
    "                train_dl = collections_dls[j][\"task_{}\".format(t)]\n",
    "                collections_idxs = next(iter(train_dl))\n",
    "\n",
    "                for c in collections_idx[0]:\n",
    "                    c = c.item()\n",
    "\n",
    "                    train_idxs = collections[c].select(\"indices\").to_numpy()[0][0].tolist()\n",
    "\n",
    "                    for t_idx in range(len(templates)):\n",
    "                        if t_idx ==  0:\n",
    "                            prompt = set_instruction_prompt(templates[t_idx], train, train_idxs, test_idx, test, instructions)\n",
    "                        else:\n",
    "                            prompt = set_prompt(templates[t_idx], train, train_idxs, test_idx, test)\n",
    "                        output = llm.run(prompt, parser_instruction)\n",
    "                        try:\n",
    "                            output = parser.parse(output)[\"answer\"]\n",
    "                        except:\n",
    "                            output = \"\"\n",
    "\n",
    "                        outputs[\"iter\"].append(i)\n",
    "                        outputs[\"template\"].append(t_idx)\n",
    "                        outputs[\"test_idx\"].append(test_idx)\n",
    "                        outputs[\"task\"].append(t)\n",
    "                        outputs[\"proportion\"].append(j)\n",
    "                        outputs[\"output\"].append(output)\n",
    "                        \n",
    "                        results = pl.DataFrame(outputs)\n",
    "                        results.write_ipc(f\"{dataset_path}/results/llama_parser.feather\")\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
