{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TACO Experiment: Cherry-picked context 2\n",
    "\n",
    "The goal here is to evaluate how the model will behave when passing the Solutions from an analog problem that were manually analyzed and selected  \n",
    "In this specific scenario we want to test it with a very specific group of tasks from the TACO benchmark  \n",
    "The difference here is try to evaluate the idea in a different task, with more tests and other metrics to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio.rhoden/miniconda3/envs/datamodels/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "## LLM\n",
    "from src.llms import GenericIntructModelHF\n",
    "from src.taco_evaluator import compute, compute_1_pass_by_test\n",
    "from datasets import load_from_disk\n",
    "import datetime\n",
    "from typing import List, Dict, Any, Tuple, Mapping\n",
    "seed = 42\n",
    "# NumPy\n",
    "np.random.seed(seed)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH  = \"../../../data/TACO/processed\"\n",
    "train = pl.read_ipc(f\"{PATH}/train.feather\")\n",
    "train_solutions = pl.read_ipc(f\"{PATH}/train_solutions.feather\")\n",
    "train_tests = pl.read_ipc(f\"{PATH}/train_evaluation_tests.feather\")\n",
    "train_dict = load_from_disk(\"../../../data/TACO/train.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(prompt: str, path: str, num_returns = 200, max_length=2048):\n",
    "    outputs = []\n",
    "    llm = GenericIntructModelHF(\"../../../models/llms/Llama-3.2-3B-Instruct\")\n",
    "    for i in range(num_returns//10):\n",
    "        print(f\"Lopp {i}, {datetime.datetime.now()}\")\n",
    "        config = {\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"max_length\": max_length,\n",
    "                    \"top_p\": 0.95,\n",
    "                    \"num_return_sequences\": 10\n",
    "        }\n",
    "        \n",
    "        instruction = \"You are a coding generation tool that will solve a problem using Python\"\n",
    "        output = llm.run(prompt=prompt, instruction=instruction, config_params=config)\n",
    "\n",
    "        for res in output:\n",
    "            outputs.append(res)\n",
    "    \n",
    "    llm.delete_model()\n",
    "    json.dump(outputs, open(path, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_generation(generations: list, id: int, path: str):\n",
    "    \n",
    "    gens = []\n",
    "    for i in range(len(generations)):\n",
    "\n",
    "        code_blocks = re.findall(r'```python(.*?)```', generations[i][\"generated_text\"], re.DOTALL)\n",
    "        extracted_code = \"\\n\".join([block.strip() for block in code_blocks])\n",
    "        gens.append(extracted_code)\n",
    "    \n",
    "    results = [{\n",
    "        \"task_id\": int(id),\n",
    "        \"output\": gens\n",
    "    }]\n",
    "\n",
    "    json.dump(results, open(path, \"w\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Selection\n",
    "\n",
    "The category choosen it was \"Probability\" in EASY difficulty  \n",
    "The criteria behind the choice is because there isn't a lot of examples of geometry, which facilitates to find samples specific from that scope.  \n",
    "The EASY difficulty is for validation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _tests = train_tests.group_by(\"id\").agg(pl.count(\"test_id\").alias(\"num_tests\"))\n",
    "# (\n",
    "#     train\n",
    "#     .join(_tests, on=\"id\", how=\"left\")\n",
    "#     .filter(pl.col(\"num_tests\") > 5)\n",
    "#     .filter(pl.col(\"tags\") == \"Probability\")\n",
    "#     .group_by(pl.col(\"difficulty\"))\n",
    "#     .agg(pl.count(\"id\"))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's the rainy season again, and the city experiences frequent showers throughout the day.\n",
      "\n",
      "The weather report says that there is a P probability of rainfalls today. Raj has to step out for a meeting at the office, and would like to know the probability that it rains during the time he is on the way.\n",
      "\n",
      "Input:\n",
      "\n",
      "The first line of input contains the number of test cases, T. Each of the following T lines contain two numbers, P and time. P denotes the probability that it will rain today and time is the time (in minutes), it will take for Raj to reach his office.\n",
      "\n",
      "Output:\n",
      "\n",
      "Output should have T lines each containing answer to corresponding test case. Please round the answer to 4 decimal places.\n",
      "\n",
      "Constraints:\n",
      "\n",
      "1 ≤ T ≤ 100\n",
      "0 ≤ P ≤ 0.5\n",
      "10 ≤ time ≤ 720\n",
      "time is a perfect divisor of 1440.\n",
      "\n",
      "SAMPLE INPUT\n",
      "2\n",
      "0 10\n",
      ".5 720\n",
      "\n",
      "SAMPLE OUTPUT\n",
      "0.0000\n",
      "0.2929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (\n",
    "#     train\n",
    "#     .join(_tests, on=\"id\", how=\"left\")\n",
    "#     .filter(pl.col(\"num_tests\") > 5)\n",
    "#     .filter(pl.col(\"tags\") == \"Probability\")\n",
    "#     .filter(pl.col(\"difficulty\") == \"MEDIUM\")\n",
    "#     .sample(1)\n",
    "# )\n",
    "## ID = 2545\n",
    "\n",
    "selected_problem = train.filter(pl.col(\"id\") == 2545)\n",
    "print(selected_problem.select([\"input\"]).unique().to_dict()[\"input\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tests.filter(pl.col(\"id\") == 2545).select(\"input\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Baseline - No Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lopp 0, 2025-03-07 16:42:37.653067\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GenericIntructModelHF.run() got an unexpected keyword argument 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt_input \u001b[38;5;241m=\u001b[39m selected_problem\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto_struct()\u001b[38;5;241m.\u001b[39mto_pandas()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease write a Python program \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQUESTION: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprompt_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m ANSWER: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno_context.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(prompt, path, num_returns, max_length)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLopp \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_length,\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.95\u001b[39m,\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_return_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m output:\n\u001b[1;32m     17\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(res)\n",
      "\u001b[0;31mTypeError\u001b[0m: GenericIntructModelHF.run() got an unexpected keyword argument 'input'"
     ]
    }
   ],
   "source": [
    "prompt_input = selected_problem.select(\"input\").to_struct().to_pandas().iloc[0][\"input\"]\n",
    "prompt = f\"Please write a Python program \\nQUESTION: \\n{prompt_input} \\n ANSWER: \\n.\"\n",
    "# run_inference(prompt_input, \"no_context.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_generation(json.load(open(\"no_context.json\")), 2545 , \"no_context_parsed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_pass_1_by_test() got an unexpected keyword argument 'file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_pass_1_by_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno_context_parsed.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2545\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno_contest_1_pass.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_contest_1_pass.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: compute_pass_1_by_test() got an unexpected keyword argument 'file'"
     ]
    }
   ],
   "source": [
    "# compute_1_pass_by_test(\"no_context_parsed.json\", [train_dict[2545]], file=\"no_context_1_pass.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Context\n",
    "\n",
    "Here we will try to get 4 solutions that are related to the problem above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 2)\n",
      "┌─────┬───────┐\n",
      "│ id  ┆ input │\n",
      "│ --- ┆ ---   │\n",
      "│ u32 ┆ u32   │\n",
      "╞═════╪═══════╡\n",
      "│ 21  ┆ 21    │\n",
      "└─────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "df = train.filter(pl.col(\"tags\") == \"Probability\").filter(pl.col(\"difficulty\") == \"MEDIUM\").select([\"id\", \"input\"])\n",
    "print(df.count())\n",
    "df.write_csv(\"pool.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>input</th><th>difficulty</th></tr><tr><td>u32</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>12872</td><td>&quot;A recent lab accident resulted…</td><td>&quot;MEDIUM&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌───────┬─────────────────────────────────┬────────────┐\n",
       "│ id    ┆ input                           ┆ difficulty │\n",
       "│ ---   ┆ ---                             ┆ ---        │\n",
       "│ u32   ┆ str                             ┆ str        │\n",
       "╞═══════╪═════════════════════════════════╪════════════╡\n",
       "│ 12872 ┆ A recent lab accident resulted… ┆ MEDIUM     │\n",
       "└───────┴─────────────────────────────────┴────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ids = [14892, 12872]\n",
    "train.filter(pl.col(\"id\") == 12872).select([\"id\", \"input\", \"difficulty\"]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>input</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Logan is cleaning his apartmen…</td></tr><tr><td>&quot;A recent lab accident resulted…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2,)\n",
       "Series: 'input' [str]\n",
       "[\n",
       "\t\"Logan is cleaning his apartmen…\n",
       "\t\"A recent lab accident resulted…\n",
       "]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs  = train.filter(pl.col(\"id\").is_in(selected_ids)).select(\"input\").unique().to_dict()[\"input\"]\n",
    "all_solutions = train_solutions.filter(pl.col(\"id\").is_in(selected_ids)).group_by(pl.col(\"id\")).head(1).select(\"solution\").unique().to_dict()[\"solution\"]\n",
    "question_input = selected_problem.select(\"input\").to_dict()[\"input\"][0]\n",
    "\n",
    "all_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>solution</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;from math import factorial\n",
       "N =…</td></tr><tr><td>&quot;MOD = 10 ** 9 + 7\n",
       "(A, B, T) = …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2,)\n",
       "Series: 'solution' [str]\n",
       "[\n",
       "\t\"from math import factorial\n",
       "N =…\n",
       "\t\"MOD = 10 ** 9 + 7\n",
       "(A, B, T) = …\n",
       "]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Prompt Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt = \"You will have to answer a programming quesiton in geometry, we will pass before some examples of questions and solutions\\n\"\n",
    "for i in range(2):\n",
    "    context_prompt += f\"EXAMPLE QUESTION {i}:\\n {all_inputs[i]}\\n EXAMPLE SOLUTION {i}:\\n {all_solutions[i]}\\n\"\n",
    "\n",
    "full_prompt = f\"Please write a Python program {context_prompt} \\nQUESTION: \\n{question_input} \\n ANSWER: \\n.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lopp 0, 2025-02-27 08:19:55.087679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio.rhoden/miniconda3/envs/datamodels/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lopp 1, 2025-02-27 08:43:58.668251\n"
     ]
    }
   ],
   "source": [
    "run_inference(\n",
    "    prompt=full_prompt,\n",
    "    path = \"full_prompt.json\",\n",
    "    num_returns=200,\n",
    "    max_length=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_generation(json.load(open(\"full_prompt.json\")), 2545 , \"full_prompt_parsed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_1_pass_by_test(\"no_context_parsed.json\", [train_dict[2545]], file=\"full_context_1_pass.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Solutions Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt = \"You will have to answer a programming quesiton in geometry, we will pass before some examples of solutions for similar problems\\n\"\n",
    "for i in range(4):\n",
    "    context_prompt += f\" EXAMPLE SOLUTION {i}:\\n {all_solutions[i]}\\n\"\n",
    "\n",
    "solutions_prompt = f\"Please write a Python program {context_prompt} \\nQUESTION: \\n{question_input} \\n ANSWER: \\n.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_inference(\n",
    "    prompt=solutions_prompt,\n",
    "    path = \"solutions_prompt.json\",\n",
    "    num_returns=20,\n",
    "    max_length=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_generation(json.load(open(\"solutions_prompt.json\")), 2545 , \"solutions_parsed.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
