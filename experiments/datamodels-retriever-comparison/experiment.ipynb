{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datamodels Retriever Experiment\n",
    "\n",
    "This document has the goal to show the implementation of a context retriever using Datamodels and its comparison against classical approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Run Classical Approaches\n",
    "\n",
    "First it's needed to run the comparison subject, to do so we will use the script present in this folder, it's just necessary to run\n",
    "\n",
    "```\n",
    "python run_classical_retriever.py\n",
    "```\n",
    "\n",
    "This will run the retriever for each sample from the test dataset, saving the data at every 50 samples as checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Data for Datamodeling\n",
    "\n",
    "Here we will be spliting the data to achieve a dev dataset containing a representative numbe of samples to each subtask\n",
    "The \"k\" used here is 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import split_dev_set, subset_df\n",
    "from src.retriever import NaiveDatamodelsRetriever\n",
    "from src.datamodels.pipeline import DatamodelPipeline\n",
    "from src.datamodels.config import DatamodelConfig, MemMapConfig\n",
    "from src.evaluator import Rouge_L_evaluator\n",
    "from src.llms import Llama3_1\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# Limit available GPUs to GPU 0 and 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"../../data/instruction-induction-data/processed/induce_tasks_examples.csv\")\n",
    "# train_subset = subset_df(train, 200, \"task\")\n",
    "# train_subset.to_csv(\"../../data/instruction-induction-data/processed/train.csv\")\n",
    "\n",
    "# split_dev_set(\n",
    "#     path=\"../../data/instruction-induction-data/processed/train.csv\",\n",
    "#     saving_path=\"../../data/instruction-induction-data/datamodels\",    \n",
    "#     k_samples=15,\n",
    "#     task_column=\"task\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the Collections to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First time create collection #####\n",
    "# retriever = DatamodelsRetriever(k=8)\n",
    "# retriever.create_collections_index(\n",
    "#     \"../../data/instruction-induction-data/datamodels_15_10_2024/train_set.csv\",\n",
    "#     \"../../data/instruction-induction-data/datamodels_15_10_2024\",\n",
    "#     n_samples=500,\n",
    "#     test_per=0.2,\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_output(text):\n",
    "    # Split the string and strip leading/trailing spaces and newlines\n",
    "    return text.split(\" Model Output:\\n \", 1)[-1].strip()\n",
    "\n",
    "df = pd.read_pickle( \"../../data/instruction-induction-data/datamodels_15_10_2024/pre_collections/15-10-2024/prcollection_0.pickle\")\n",
    "\n",
    "\n",
    "result = Rouge_L_evaluator().evaluate(df[\"true_output\"].to_numpy(),  df[\"predicted_output\"].apply(extract_output).to_numpy(), datamodel.llm.tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_idx</th>\n",
       "      <th>test_idx</th>\n",
       "      <th>input</th>\n",
       "      <th>predicted_output</th>\n",
       "      <th>true_output</th>\n",
       "      <th>optinal_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>The presidents did not recognize the scientist.</td>\n",
       "      <td>The scientist was recognized by the presidents.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>The senators mentioned the artists.</td>\n",
       "      <td>The artists were mentioned by the senators.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td></td>\n",
       "      <td>The secretaries were avoided by the lawyer.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>The athletes were introduced by the presidents...</td>\n",
       "      <td>The athletes were introduced by the presidents.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>The student was helped by the scientists.\\n\\n ...</td>\n",
       "      <td>The student was helped by the scientists.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>know\\n            User Input:\\n            Sen...</td>\n",
       "      <td>same</td>\n",
       "      <td>['same', 'yes', 'true']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Please inspect your father's will carefully. W...</td>\n",
       "      <td>same</td>\n",
       "      <td>['same', 'yes', 'true']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>o</td>\n",
       "      <td>not the same</td>\n",
       "      <td>['not the same', 'no', 'false']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>h\\n\\n            User Input:\\n            Sent...</td>\n",
       "      <td>same</td>\n",
       "      <td>['same', 'yes', 'true']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>c\\n\\n            User Input:\\n            Sent...</td>\n",
       "      <td>same</td>\n",
       "      <td>['same', 'yes', 'true']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     collection_idx  test_idx  \\\n",
       "0                 0         0   \n",
       "1                 0         1   \n",
       "2                 0         2   \n",
       "3                 0         3   \n",
       "4                 0         4   \n",
       "..              ...       ...   \n",
       "100               0       100   \n",
       "101               0       101   \n",
       "102               0       102   \n",
       "103               0       103   \n",
       "104               0       104   \n",
       "\n",
       "                                                 input  \\\n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                 ...   \n",
       "100  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "101  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "102  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "103  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "104  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      predicted_output  \\\n",
       "0      The presidents did not recognize the scientist.   \n",
       "1                  The senators mentioned the artists.   \n",
       "2                                                        \n",
       "3    The athletes were introduced by the presidents...   \n",
       "4    The student was helped by the scientists.\\n\\n ...   \n",
       "..                                                 ...   \n",
       "100  know\\n            User Input:\\n            Sen...   \n",
       "101  Please inspect your father's will carefully. W...   \n",
       "102                                                  o   \n",
       "103  h\\n\\n            User Input:\\n            Sent...   \n",
       "104  c\\n\\n            User Input:\\n            Sent...   \n",
       "\n",
       "                                         true_output  \\\n",
       "0    The scientist was recognized by the presidents.   \n",
       "1        The artists were mentioned by the senators.   \n",
       "2        The secretaries were avoided by the lawyer.   \n",
       "3    The athletes were introduced by the presidents.   \n",
       "4          The student was helped by the scientists.   \n",
       "..                                               ...   \n",
       "100                                             same   \n",
       "101                                             same   \n",
       "102                                     not the same   \n",
       "103                                             same   \n",
       "104                                             same   \n",
       "\n",
       "                      optinal_output  \n",
       "0                               None  \n",
       "1                               None  \n",
       "2                               None  \n",
       "3                               None  \n",
       "4                               None  \n",
       "..                               ...  \n",
       "100          ['same', 'yes', 'true']  \n",
       "101          ['same', 'yes', 'true']  \n",
       "102  ['not the same', 'no', 'false']  \n",
       "103          ['same', 'yes', 'true']  \n",
       "104          ['same', 'yes', 'true']  \n",
       "\n",
       "[105 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection = pd.read_feather(\"../../data/instruction-induction-data/datamodels/proportion_study/210_5/pre_collections/__pre_collection_0.feather\")\n",
    "df_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>possible_outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The lawyer avoided the secretaries.</td>\n",
       "      <td>The secretaries were avoided by the lawyer.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The judges supported the scientists.</td>\n",
       "      <td>The scientists were supported by the judges.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The secretary recommended the professor.</td>\n",
       "      <td>The professor was recommended by the secretary.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The artists recommended the secretary.</td>\n",
       "      <td>The secretary was recommended by the artists.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The secretary avoided the senator.</td>\n",
       "      <td>The senator was avoided by the secretary.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                task                                     input  \\\n",
       "0  active_to_passive       The lawyer avoided the secretaries.   \n",
       "1  active_to_passive      The judges supported the scientists.   \n",
       "2  active_to_passive  The secretary recommended the professor.   \n",
       "3  active_to_passive    The artists recommended the secretary.   \n",
       "4  active_to_passive        The secretary avoided the senator.   \n",
       "\n",
       "                                            output possible_outputs  \n",
       "0      The secretaries were avoided by the lawyer.              NaN  \n",
       "1     The scientists were supported by the judges.              NaN  \n",
       "2  The professor was recommended by the secretary.              NaN  \n",
       "3    The secretary was recommended by the artists.              NaN  \n",
       "4        The senator was avoided by the secretary.              NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traind_df = pd.read_csv(\"../../data/instruction-induction-data/datamodels_15_10_2024/train_set.csv\")\n",
    "traind_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>possible_outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The judge mentioned the manager.</td>\n",
       "      <td>The manager was mentioned by the judge.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The professors encouraged the presidents.</td>\n",
       "      <td>The presidents were encouraged by the professors.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The banker recommended the secretary.</td>\n",
       "      <td>The secretary was recommended by the banker.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The secretaries thanked the presidents.</td>\n",
       "      <td>The presidents were thanked by the secretaries.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>The bankers recognized the doctor.</td>\n",
       "      <td>The doctor was recognized by the bankers.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                task                                      input  \\\n",
       "0  active_to_passive           The judge mentioned the manager.   \n",
       "1  active_to_passive  The professors encouraged the presidents.   \n",
       "2  active_to_passive      The banker recommended the secretary.   \n",
       "3  active_to_passive    The secretaries thanked the presidents.   \n",
       "4  active_to_passive         The bankers recognized the doctor.   \n",
       "\n",
       "                                              output possible_outputs  \n",
       "0            The manager was mentioned by the judge.              NaN  \n",
       "1  The presidents were encouraged by the professors.              NaN  \n",
       "2       The secretary was recommended by the banker.              NaN  \n",
       "3    The presidents were thanked by the secretaries.              NaN  \n",
       "4          The doctor was recognized by the bankers.              NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df = pd.read_csv(\"../../data/instruction-induction-data/datamodels_15_10_2024/dev_set.csv\")\n",
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_idx</th>\n",
       "      <th>test_idx</th>\n",
       "      <th>input</th>\n",
       "      <th>predicted_output</th>\n",
       "      <th>true_output</th>\n",
       "      <th>optinal_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>\\n            Fill the expected Output accordi...</td>\n",
       "      <td>The manager was mentioned by the judge.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>\\n            Fill the expected Output accordi...</td>\n",
       "      <td>The presidents were encouraged by the professors.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>\\n            Fill the expected Output accordi...</td>\n",
       "      <td>The secretary was recommended by the banker.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>\\n            Fill the expected Output accordi...</td>\n",
       "      <td>The presidents were thanked by the secretaries.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>\\n            Fill the expected Output accordi...</td>\n",
       "      <td>The doctor was recognized by the bankers.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_idx  test_idx  \\\n",
       "0               0         0   \n",
       "1               0         1   \n",
       "2               0         2   \n",
       "3               0         3   \n",
       "4               0         4   \n",
       "\n",
       "                                               input  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    predicted_output  \\\n",
       "0  \\n            Fill the expected Output accordi...   \n",
       "1  \\n            Fill the expected Output accordi...   \n",
       "2  \\n            Fill the expected Output accordi...   \n",
       "3  \\n            Fill the expected Output accordi...   \n",
       "4  \\n            Fill the expected Output accordi...   \n",
       "\n",
       "                                         true_output optinal_output  \n",
       "0            The manager was mentioned by the judge.            NaN  \n",
       "1  The presidents were encouraged by the professors.            NaN  \n",
       "2       The secretary was recommended by the banker.            NaN  \n",
       "3    The presidents were thanked by the secretaries.            NaN  \n",
       "4          The doctor was recognized by the bankers.            NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_collection = pd.read_pickle( \"../../data/instruction-induction-data/datamodels_15_10_2024/pre_collections/15-10-2024/pre_collection_10.pickle\")\n",
    "pre_collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_idx</th>\n",
       "      <th>test_idx</th>\n",
       "      <th>input</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_idx  test_idx  \\\n",
       "0               0         0   \n",
       "1               0         1   \n",
       "2               0         2   \n",
       "3               0         3   \n",
       "4               0         4   \n",
       "\n",
       "                                               input  evaluation  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    1.000000  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    0.714286  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    1.000000  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    0.823529  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...    0.777778  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = pd.read_pickle( \"../../data/instruction-induction-data/datamodels_15_10_2024/collections/15-10-2024/pre_collection_10.pickle\")\n",
    "collection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Sample Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59303/1521282305.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample[\"evaluation\"] = collection.copy().loc[0][\"evaluation\"]\n",
      "/tmp/ipykernel_59303/1521282305.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample[\"evaluation\"] = collection.copy().loc[0][\"evaluation\"]\n",
      "/tmp/ipykernel_59303/1521282305.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample[\"task\"] = dev_df.loc[sample[\"test_idx\"]][\"task\"]\n",
      "/tmp/ipykernel_59303/1521282305.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample[\"task\"] = dev_df.loc[sample[\"test_idx\"]][\"task\"]\n"
     ]
    }
   ],
   "source": [
    "### Anlyse a sing sample\n",
    "sample = pre_collection.loc[0]\n",
    "sample[\"evaluation\"] = collection.copy().loc[0][\"evaluation\"]\n",
    "sample[\"task\"] = dev_df.loc[sample[\"test_idx\"]][\"task\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Fill the expected Output according to the instruction\n",
      "            Intruction: Write the input sentence in passive form.\n",
      "\n",
      "            Examples:\n",
      "            Input: 5040 \n",
      "Output: five thousand and forty\n",
      "Input: 1 64 \n",
      "Output: 65\n",
      "Input: grenade \n",
      "Output: r\n",
      "Input: Sentence 1: A school bus is driving uphill on a rural road. Sentence 2: A race care driving along a dirt road. \n",
      "Output: 1 - probably not\n",
      "Input: souvenir \n",
      "Output: near\n",
      "Input: The student recognized the professors. \n",
      "Output: The professors were recognized by the student.\n",
      "Input: Sentence 1: White House in damage control over Obama Supreme Court remarks Sentence 2: Fact check: Obama's Supreme Court remarks \n",
      "Output: 4 - almost perfectly\n",
      "Input: camouflage \n",
      "Output: c\n",
      "\n",
      "\n",
      "            User Input:\n",
      "            The judge mentioned the manager.\n",
      "\n",
      "            Model Output:\n",
      "         The manager was mentioned by the judge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"predicted_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The manager was mentioned by the judge.\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"true_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sample[\"evaluation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results by Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pre_collection.copy()\n",
    "samples[\"evaluation\"] = collection[\"evaluation\"]\n",
    "samples[\"task\"] = samples[\"test_idx\"].apply(lambda idx: dev_df.loc[idx, 'task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task\n",
       "active_to_passive          165\n",
       "antonyms                   165\n",
       "diff                       165\n",
       "first_word_letter          165\n",
       "larger_animal              165\n",
       "letters_list               165\n",
       "negation                   165\n",
       "num_to_verbal              165\n",
       "orthography_starts_with    165\n",
       "rhymes                     165\n",
       "second_word_letter         165\n",
       "sentence_similarity        165\n",
       "sentiment                  165\n",
       "singular_to_plural         165\n",
       "sum                        165\n",
       "synonyms                   165\n",
       "taxonomy_animal            165\n",
       "translation_en-de          165\n",
       "translation_en-es          165\n",
       "translation_en-fr          165\n",
       "word_in_context            165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[\"task\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_results = samples.groupby('task').agg(\n",
    "    mean=('evaluation', 'mean'),\n",
    "    q25=('evaluation', lambda x: x.quantile(0.25)),\n",
    "    q50=('evaluation', lambda x: x.quantile(0.50)),  # Same as median\n",
    "    q75=('evaluation', lambda x: x.quantile(0.75)),\n",
    "    q100=('evaluation', lambda x: x.quantile(1.00))\n",
    ").reset_index()\n",
    "\n",
    "len(task_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>mean</th>\n",
       "      <th>q25</th>\n",
       "      <th>q50</th>\n",
       "      <th>q75</th>\n",
       "      <th>q100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>active_to_passive</td>\n",
       "      <td>0.498462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antonyms</td>\n",
       "      <td>0.074574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diff</td>\n",
       "      <td>0.331053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first_word_letter</td>\n",
       "      <td>0.136107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>larger_animal</td>\n",
       "      <td>0.349500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>letters_list</td>\n",
       "      <td>0.241986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negation</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_to_verbal</td>\n",
       "      <td>0.428086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>orthography_starts_with</td>\n",
       "      <td>0.164283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rhymes</td>\n",
       "      <td>0.254800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>second_word_letter</td>\n",
       "      <td>0.033753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentence_similarity</td>\n",
       "      <td>0.120356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.094441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>singular_to_plural</td>\n",
       "      <td>0.267567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sum</td>\n",
       "      <td>0.182097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>synonyms</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>taxonomy_animal</td>\n",
       "      <td>0.298644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>translation_en-de</td>\n",
       "      <td>0.074291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>translation_en-es</td>\n",
       "      <td>0.056964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>translation_en-fr</td>\n",
       "      <td>0.101938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>word_in_context</td>\n",
       "      <td>0.028324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       task      mean       q25       q50       q75  q100\n",
       "0         active_to_passive  0.498462  0.000000  0.500000  0.823529  1.00\n",
       "1                  antonyms  0.074574  0.000000  0.000000  0.000000  1.00\n",
       "2                      diff  0.331053  0.000000  0.285714  0.400000  1.00\n",
       "3         first_word_letter  0.136107  0.000000  0.000000  0.166667  1.00\n",
       "4             larger_animal  0.349500  0.000000  0.285714  0.666667  1.00\n",
       "5              letters_list  0.241986  0.000000  0.000000  0.571429  1.00\n",
       "6                  negation  0.521000  0.266667  0.588235  0.800000  1.00\n",
       "7             num_to_verbal  0.428086  0.000000  0.500000  0.800000  1.00\n",
       "8   orthography_starts_with  0.164283  0.000000  0.181818  0.222222  1.00\n",
       "9                    rhymes  0.254800  0.000000  0.000000  0.400000  1.00\n",
       "10       second_word_letter  0.033753  0.000000  0.000000  0.000000  0.40\n",
       "11      sentence_similarity  0.120356  0.000000  0.000000  0.222222  1.00\n",
       "12                sentiment  0.094441  0.000000  0.000000  0.000000  1.00\n",
       "13       singular_to_plural  0.267567  0.000000  0.000000  0.333333  1.00\n",
       "14                      sum  0.182097  0.000000  0.000000  0.333333  1.00\n",
       "15                 synonyms  0.002424  0.000000  0.000000  0.000000  0.40\n",
       "16          taxonomy_animal  0.298644  0.000000  0.363636  0.500000  0.75\n",
       "17        translation_en-de  0.074291  0.000000  0.000000  0.000000  1.00\n",
       "18        translation_en-es  0.056964  0.000000  0.000000  0.000000  1.00\n",
       "19        translation_en-fr  0.101938  0.000000  0.000000  0.000000  1.00\n",
       "20          word_in_context  0.028324  0.000000  0.000000  0.000000  0.40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
